{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data preprocessing\n",
    "\n",
    "train_set=[]\n",
    "test_set = []\n",
    "\n",
    "with open('reviewstrain.txt') as f:\n",
    "    for l in f.readlines():\n",
    "        label = int(l[0])\n",
    "        train_set.append((label,l[2:]))\n",
    "\n",
    "with open('reviewstest.txt') as f:\n",
    "     for l in f.readlines():\n",
    "        label = int(l[0])\n",
    "        comment = l[2:]\n",
    "        test_set.append((label, comment))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_token_dict(X):\n",
    "    token_dict = collections.defaultdict(set)\n",
    "    idx = 0\n",
    "    for i in range(len(X)):\n",
    "        for c in X[i][1].split():\n",
    "            token_dict[c].add(i)\n",
    "    return token_dict\n",
    "\n",
    "def find_knn_label(k, sentence, token_dict):\n",
    "    ctr = collections.defaultdict(int)\n",
    "    for token in sentence.split():\n",
    "        candidates=token_dict[token]\n",
    "        for cand in candidates:\n",
    "            ctr[cand]+=1\n",
    "    s = sorted([k for k in ctr.keys()], key=lambda x:ctr[x], reverse=True)\n",
    "    k_label = s[:k]\n",
    "    lcount = collections.Counter([train_set[l][0] for l in k_label])\n",
    "    ke = max(lcount.items(), key=lambda x:x[1])[1]\n",
    "    idx_label = [i for i,v in lcount.items() if v==ke]\n",
    "    if len(idx_label)==1:\n",
    "        return idx_label[0]\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "def get_label(s):\n",
    "    y = []\n",
    "    for i in range(len(s)):\n",
    "        y.append(s[i][0])\n",
    "    return y\n",
    "\n",
    "def predict(k, testset, token_dict):\n",
    "    _y = []\n",
    "    for i in range(len(testset)):\n",
    "        label = find_knn_label(k, testset[i][1], token_dict)\n",
    "        _y.append(label)\n",
    "    return _y\n",
    "\n",
    "def get_matrix(y, _y):\n",
    "    tp, fn, fp, tn = 0,0,0,0\n",
    "    for i in range(len(y)):\n",
    "        if  y[i]:\n",
    "            if _y[i]:\n",
    "                tp += 1\n",
    "            else:\n",
    "                fn += 1\n",
    "        else:\n",
    "            if _y[i]:\n",
    "                fp += 1\n",
    "            else:\n",
    "                tn += 1\n",
    "    return [[tp, fn], [fp, tn]]\n",
    "\n",
    "def cal_tp_rate(m):\n",
    "    return m[0][0]/(m[0][0]+m[0][1])\n",
    "\n",
    "def cal_fp_rate(m):\n",
    "    return m[1][0]/(m[1][0]+m[1][1])\n",
    "\n",
    "def cal_corrects(y, _y):\n",
    "    n = len(y)\n",
    "    corr = 0\n",
    "    for i in range(n):\n",
    "        if y[i] == _y[i]:\n",
    "            corr += 1\n",
    "    return corr\n",
    "\n",
    "def cal_acc(y, _y):\n",
    "    return cal_corrects(y, _y)/len(y)\n",
    "\n",
    "def find_k(X, kset):\n",
    "    N = len(X)\n",
    "    v_size = N//5\n",
    "    corrects = collections.defaultdict()\n",
    "    for k in kset:\n",
    "        all_corr = 0\n",
    "        for i in range(0, N, v_size):\n",
    "            Xt = X[:i] + X[i+v_size:]\n",
    "            Xv = X[i:i+v_size]\n",
    "            yt = get_label(Xt)\n",
    "            yv = get_label(Xv)\n",
    "            temp_token_dict = get_token_dict(Xt)\n",
    "            _y = predict(k, Xv, temp_token_dict)\n",
    "            all_corr += cal_corrects(yv, _y)\n",
    "        corrects[k] = all_corr\n",
    "        print('k=', k, 'corrects=', all_corr, 'accuracy=', all_corr/N)\n",
    "    return max(corrects.items(), key=lambda x:x[1])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5861"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_token_dict = get_token_dict(train_set)\n",
    "len(all_token_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = get_label(test_set)\n",
    "_y_test1 = predict(1, test_set, all_token_dict)\n",
    "_y_test5 = predict(5, test_set, all_token_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Line 18 of test file is: (1, 'it leaves little doubt that kidman has become one of our best actors .\\t\\n')\n",
      "Predicted label it is 1\n"
     ]
    }
   ],
   "source": [
    "print('Line 18 of test file is:', test_set[17])\n",
    "print('Predicted label it is', _y_test1[17])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Line 18 of test file is: (1, 'it leaves little doubt that kidman has become one of our best actors .\\t\\n')\n",
      "Predicted label it is 1\n"
     ]
    }
   ],
   "source": [
    "print('Line 18 of test file is:', test_set[17])\n",
    "print('Predicted label it is', _y_test5[17])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[189, 84], [118, 109]]"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[[201, 72], [123, 104]]"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_matrix(y_test, _y_test1)\n",
    "get_matrix(y_test, _y_test5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accruracy of test set when k=1 is: 0.596\n",
      "The true positive rate of test set when k=1 is: 0.6923076923076923\n",
      "The false positive rate of test set when k=1 is: 0.5198237885462555\n"
     ]
    }
   ],
   "source": [
    "print('The accruracy of test set when k=1 is:', cal_acc(y_test, _y_test1))\n",
    "print('The true positive rate of test set when k=1 is:', cal_tp_rate(get_matrix(y_test, _y_test1)))\n",
    "print('The false positive rate of test set when k=1 is:', cal_fp_rate(get_matrix(y_test, _y_test1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accruracy of test set when k=5 is: 0.61\n",
      "The true positive rate of test set when k=5 is: 0.7362637362637363\n",
      "The false positive rate of test set when k=5 is: 0.5418502202643172\n"
     ]
    }
   ],
   "source": [
    "print('The accruracy of test set when k=5 is:', cal_acc(y_test, _y_test5))\n",
    "print('The true positive rate of test set when k=5 is:', cal_tp_rate(get_matrix(y_test, _y_test5)))\n",
    "print('The false positive rate of test set when k=5 is:', cal_fp_rate(get_matrix(y_test, _y_test5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[273, 0], [227, 0]]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = get_label(train_set)\n",
    "y_ZR = [1]*len(y_test) if sum(y_train)>(len(y_train)/2) else [0]*len(y_test)\n",
    "get_matrix(y_test, y_ZR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k= 3 corrects= 875 accuracy= 0.5833333333333334\n",
      "k= 7 corrects= 897 accuracy= 0.598\n",
      "k= 99 corrects= 827 accuracy= 0.5513333333333333\n"
     ]
    }
   ],
   "source": [
    "best_k = find_k(train_set, [3,7,99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "_y_train = predict(best_k, train_set, all_token_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.776"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cal_acc(y_train, _y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[231, 42], [162, 65]]"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.592"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_train_set = []\n",
    "for i in range(1500):\n",
    "    c_train_set.append((_y_train[i], train_set[i][1]))\n",
    "train_set = c_train_set\n",
    "_y_test7 = predict(best_k, test_set, all_token_dict)\n",
    "get_matrix(y_test, _y_test7)\n",
    "cal_acc(y_test, _y_test7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_knn_label_d(k, sentence, token_dict):\n",
    "    ctr = collections.defaultdict(int)\n",
    "    for token in sentence.split():\n",
    "        candidates=token_dict[token]\n",
    "        for cand in candidates:\n",
    "            if cand!='.' and cand!=',':\n",
    "                ctr[cand]+=1\n",
    "    if len(ctr)==0:\n",
    "        return 1\n",
    "    s = sorted([k for k in ctr.keys()], key=lambda x:ctr[x], reverse=True)\n",
    "    k_label = s[:k]\n",
    "    lcount = collections.Counter([train_set[l][0] for l in k_label])\n",
    "    ke = max(lcount.items(), key=lambda x:x[1])[1]\n",
    "    idx_label = [i for i,v in lcount.items() if v==ke]\n",
    "    if len(idx_label)==1:\n",
    "        return idx_label[0]\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "def predict_d(k, testset, token_dict):\n",
    "    _y = []\n",
    "    for i in range(len(testset)):\n",
    "#         print(i)\n",
    "        label = find_knn_label_d(k, testset[i][1], token_dict)\n",
    "        _y.append(label)\n",
    "    return _y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_token_dict = get_token_dict(train_set)\n",
    "del c_token_dict[',']\n",
    "del c_token_dict['.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "_y_d1 = predict_d(1, test_set, c_token_dict)\n",
    "_y_d5 = predict_d(5, test_set, c_token_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[181, 92], [117, 110]]"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_matrix(y_test, _y_d1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accruracy of test set when k=1 is: 0.582\n",
      "The true positive rate of test set when k=1 is: 0.663003663003663\n",
      "The false positive rate of test set when k=1 is: 0.5154185022026432\n"
     ]
    }
   ],
   "source": [
    "print('The accruracy of test set when k=1 is:', cal_acc(y_test, _y_d1))\n",
    "print('The true positive rate of test set when k=1 is:', cal_tp_rate(get_matrix(y_test, _y_d1)))\n",
    "print('The false positive rate of test set when k=1 is:', cal_fp_rate(get_matrix(y_test, _y_d1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[197, 76], [111, 116]]"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_matrix(y_test, _y_d5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accruracy of test set when k=5 is: 0.626\n",
      "The true positive rate of test set when k=5 is: 0.7216117216117216\n",
      "The false positive rate of test set when k=5 is: 0.4889867841409692\n"
     ]
    }
   ],
   "source": [
    "print('The accruracy of test set when k=5 is:', cal_acc(y_test, _y_d5))\n",
    "print('The true positive rate of test set when k=5 is:', cal_tp_rate(get_matrix(y_test, _y_d5)))\n",
    "print('The false positive rate of test set when k=5 is:', cal_fp_rate(get_matrix(y_test, _y_d5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
